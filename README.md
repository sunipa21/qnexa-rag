# Qnexa AI ‚Äî Intelligent Knowledge Management

![React](https://img.shields.io/badge/React-19-61DAFB?style=flat&logo=react&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-5.9-3178C6?style=flat&logo=typescript&logoColor=white)
![Vite](https://img.shields.io/badge/Vite-7.x-646CFF?style=flat&logo=vite&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

**Qnexa AI** is a privacy-first, fully client-side Knowledge Management application that transforms how you interact with AI. Upload your documents, add web content, and have intelligent, context-aware conversations ‚Äî all without a backend server.

Your data never leaves your device unless you choose a cloud LLM provider.

---

## üé• Demo

<video src="https://github.com/user-attachments/assets/fe37707c-db14-4673-9e15-5e4d52d1d2da" controls="controls" style="max-width: 100%;">
</video>

---

## ‚ú® Features

| Feature | Description |
|---|---|
| ü§ñ **Multi-Provider LLM** | OpenAI, Google Gemini, and Ollama (local) ‚Äî switch seamlessly |
| üß† **RAG Knowledge Base** | Upload PDFs, add URLs, then query across all your content |
| üîí **Privacy-First** | 100% client-side; API keys never touch a backend server |
| üéôÔ∏è **Voice I/O** | Speak your queries; listen to AI responses via TTS |
| ‚ö° **Local Embeddings** | In-browser vector embeddings via `@xenova/transformers` ‚Äî no API key needed |
| üóÇÔ∏è **Dual Vector Store** | ChromaDB as primary, IndexedDB as automatic offline fallback |
| üìÑ **Document Processing** | PDF text extraction and web page scraping built-in |
| üåä **Streaming Responses** | Real-time token-by-token response rendering with Markdown support |

---

## üèóÔ∏è Architecture

Qnexa AI is a **zero-backend, client-side RAG (Retrieval-Augmented Generation)** application:

```
User Input
    ‚îÇ
    ‚ñº
[Embed Query]  ‚îÄ‚îÄ‚Üí  @xenova/transformers | OpenAI | Gemini
    ‚îÇ
    ‚ñº
[Vector Search]  ‚îÄ‚îÄ‚Üí  ChromaDB (primary) / IndexedDB (fallback)
    ‚îÇ
    ‚ñº
[Retrieve Top-K Chunks]
    ‚îÇ
    ‚ñº
[Construct Prompt]  ‚îÄ‚îÄ‚Üí  System Prompt + Retrieved Context + User Query
    ‚îÇ
    ‚ñº
[LLM Inference]  ‚îÄ‚îÄ‚Üí  OpenAI / Google Gemini / Ollama (local)
    ‚îÇ
    ‚ñº
[Stream Response]  ‚îÄ‚îÄ‚Üí  Markdown rendered in real-time
```

**Key Design Decisions:**
- No proprietary backend ‚Äî direct browser ‚Üî LLM provider communication.
- Dual vector store with automatic fallback for offline resilience.
- All API keys stored in browser `localStorage` and sent only to their respective providers.

---

## üõ†Ô∏è Tech Stack

### Core Framework
| Technology | Version | Role |
|---|---|---|
| [React](https://react.dev/) | 19.x | UI component framework |
| [TypeScript](https://www.typescriptlang.org/) | 5.9.x | Type-safe development |
| [Vite](https://vitejs.dev/) | 7.x | Build tool & dev server |

### AI & Machine Learning
| Technology | Role |
|---|---|
| [@xenova/transformers](https://huggingface.co/docs/transformers.js) | In-browser embeddings (WebAssembly, no API key) |
| [OpenAI API](https://platform.openai.com/) | GPT models + OpenAI embeddings |
| [Google Gemini API](https://ai.google.dev/) | Gemini models + Gemini embeddings |
| [Ollama](https://ollama.com/) | Local LLM inference (Llama 3, Mistral, etc.) |

### Storage & Vector Search
| Technology | Role |
|---|---|
| [ChromaDB](https://www.trychroma.com/) | Primary vector database |
| IndexedDB | Browser-native fallback vector store |
| LocalStorage | User settings & API key persistence |

### Document Processing
| Technology | Role |
|---|---|
| [pdfjs-dist](https://mozilla.github.io/pdf.js/) | PDF text extraction |
| Custom Web Scraper | HTML content extraction from URLs |

### Rendering
| Technology | Role |
|---|---|
| [react-markdown](https://github.com/remarkjs/react-markdown) | Markdown rendering for AI responses |
| [remark-gfm](https://github.com/remarkjs/remark-gfm) | GitHub Flavored Markdown support (tables, task lists) |

---

## üöÄ Getting Started

### Prerequisites

- **Node.js** v18 or higher ([Download](https://nodejs.org/))
- **Ollama** *(optional ‚Äî only for local LLMs)*: [Download Ollama](https://ollama.com/)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/sunipa21/AI_Enabled_Knowledge_Management.git
cd AI_Enabled_Knowledge_Management

# 2. Install dependencies
npm install

# 3. Start the development server
npm run dev
```

Open **http://localhost:5173** in your browser.

### Production Build

```bash
npm run build       # Outputs to dist/
npm run preview     # Preview the production build locally
```

---

## ‚öôÔ∏è Configuration

All configuration is done inside the app's **Settings panel** (click the ‚öôÔ∏è gear icon).

### LLM Providers

| Provider | Setup |
|---|---|
| **OpenAI** | Paste your [OpenAI API Key](https://platform.openai.com/api-keys) |
| **Google Gemini** | Paste your [Gemini API Key](https://aistudio.google.com/app/apikey) |
| **Ollama (Local)** | Run Ollama locally ‚Äî no API key required |

### Ollama CORS Setup

If using Ollama, you must allow browser-based requests:

```bash
# macOS / Linux
OLLAMA_ORIGINS="*" ollama serve

# Windows (PowerShell)
$env:OLLAMA_ORIGINS="*"; ollama serve
```

Then pull a model:

```bash
ollama pull llama3        # Recommended
ollama pull mistral       # Alternative
```

### Embedding Providers

Configure in Settings ‚Üí Embeddings:
- **Transformers.js** ‚Äî Fully local, no API key required *(recommended default)*
- **OpenAI Embeddings** ‚Äî Requires OpenAI API key
- **Gemini Embeddings** ‚Äî Requires Gemini API key

---

## üì∏ Screenshots

**Settings Interface:**

![Settings ‚Äî HuggingFace](https://github.com/user-attachments/assets/08c31ca7-5af0-4d86-a836-53851bbf7918)
![Settings ‚Äî Ollama](https://github.com/user-attachments/assets/af46189d-c553-4d31-a1a4-040b48374f94)

---

## üìÇ Project Structure

```
AI_Enabled_Knowledge_Management/
‚îú‚îÄ‚îÄ public/                     # Static assets
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/             # UI components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.tsx   # Main chat UI with streaming
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ KnowledgeBase.tsx   # Document management panel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Settings.tsx        # Settings & config panel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SettingsModal.tsx   # Modal wrapper for settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VoiceInput.tsx      # Voice input component
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useVoice.ts         # Voice interaction hook
‚îÇ   ‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chroma-default-embed.ts  # ChromaDB no-op embedding shim
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm/                # LLM provider integrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini.ts       # Google Gemini integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ huggingface.ts  # HuggingFace integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts        # Provider router
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama.ts       # Ollama integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai.ts       # OpenAI integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chroma-db.ts        # ChromaDB vector store
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.ts       # Embedding provider abstraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge-base.ts   # RAG orchestration logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf-parser.ts       # PDF text extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech-recognition.ts  # Browser speech API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text-to-speech.ts   # TTS service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector-db.ts        # IndexedDB vector store (fallback)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web-scraper.ts      # URL content extractor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web-search.ts       # Web search integration
‚îÇ   ‚îú‚îÄ‚îÄ types.ts                # Shared TypeScript types
‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                 # Root application component
‚îÇ   ‚îî‚îÄ‚îÄ main.tsx                # Entry point
‚îú‚îÄ‚îÄ docs/                       # Project wiki
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ vite.config.ts
```

---

## üåê Hosting & Scaling

Qnexa AI is a **fully static application** ‚Äî the server only delivers HTML, CSS, and JavaScript files. Everything else runs inside the user's own browser.

**Zero server cost at any scale.** Deploy the `dist/` folder to any static host (Vercel, Netlify, GitHub Pages, S3). 100 concurrent users means zero shared server state and zero cross-user conflict ‚Äî each user's API key, knowledge base, and settings live entirely within their own browser's `localStorage` and `IndexedDB`.

> ‚ö†Ô∏è **Bring Your Own Key (BYOK)**
> Each user must supply their own API key (OpenAI, Gemini, or HuggingFace) via the Settings panel before using the app. Keys are stored locally in their browser and sent **directly** to the chosen LLM provider ‚Äî they never pass through any intermediary server. If a user switches devices or browsers, they will need to re-enter their key.

For usage with **Ollama**, no API key is required ‚Äî the app connects to the user's locally running Ollama instance.

---

## üó∫Ô∏è Roadmap

- [ ] Support for more document formats (DOCX, TXT, Markdown)
- [ ] Export and import knowledge base
- [ ] Export chat conversations
- [ ] Advanced filtering and search options
- [ ] Document folders and tagging
- [ ] Multi-language support
- [ ] Mobile-responsive layout enhancements
- [ ] Cloud sync for knowledge base (opt-in)
- [ ] Collaborative shared knowledge bases

---

## ü§ù Contributing

Contributions are welcome! Here's how to get started:

1. **Fork** the repository
2. **Create a branch**: `git checkout -b feature/your-feature-name`
3. **Commit your changes**: `git commit -m 'feat: add your feature'`
4. **Push to branch**: `git push origin feature/your-feature-name`
5. **Open a Pull Request** against `main`

Please ensure your code follows the existing TypeScript patterns and passes the linter:

```bash
npm run lint
```

---

## üìÑ License

This project is licensed under the **MIT License**. See [LICENSE](LICENSE) for details.

---

## üìö Documentation

Full documentation is available in the [`docs/`](docs/Home.md) directory:

- [Getting Started](docs/Getting-Started.md)
- [Architecture](docs/Architecture.md)
- [Features](docs/Features.md)
- [API Reference](docs/API-Reference.md)
- [Git Workflow](docs/Git-Workflow.md)
