# Qnexa AI â€” Intelligent Knowledge Management

![React](https://img.shields.io/badge/React-19-61DAFB?style=flat&logo=react&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-5.9-3178C6?style=flat&logo=typescript&logoColor=white)
![Vite](https://img.shields.io/badge/Vite-7.x-646CFF?style=flat&logo=vite&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

**Qnexa AI** is a privacy-first, fully client-side Knowledge Management application that transforms how you interact with AI. Upload your documents, add web content, and have intelligent, context-aware conversations â€” all without a backend server.

Your data never leaves your device unless you choose a cloud LLM provider.

---

## ğŸ¥ Demo

<video src="https://github.com/user-attachments/assets/fe37707c-db14-4673-9e15-5e4d52d1d2da" controls="controls" style="max-width: 100%;">
</video>

---

## âœ¨ Features

| Feature | Description |
|---|---|
| ğŸ¤– **Multi-Provider LLM** | OpenAI, Google Gemini, and Ollama (local) â€” switch seamlessly |
| ğŸ§  **RAG Knowledge Base** | Upload PDFs, add URLs, then query across all your content |
| ğŸ”’ **Privacy-First** | 100% client-side; API keys never touch a backend server |
| ğŸ™ï¸ **Voice I/O** | Speak your queries; listen to AI responses via TTS |
| âš¡ **Local Embeddings** | In-browser vector embeddings via `@xenova/transformers` â€” no API key needed |
| ğŸ—‚ï¸ **Dual Vector Store** | ChromaDB as primary, IndexedDB as automatic offline fallback |
| ğŸ“„ **Document Processing** | PDF text extraction and web page scraping built-in |
| ğŸŒŠ **Streaming Responses** | Real-time token-by-token response rendering with Markdown support |

---

## ğŸ—ï¸ Architecture

Qnexa AI is a **zero-backend, client-side RAG (Retrieval-Augmented Generation)** application:

```
User Input
    â”‚
    â–¼
[Embed Query]  â”€â”€â†’  @xenova/transformers | OpenAI | Gemini
    â”‚
    â–¼
[Vector Search]  â”€â”€â†’  ChromaDB (primary) / IndexedDB (fallback)
    â”‚
    â–¼
[Retrieve Top-K Chunks]
    â”‚
    â–¼
[Construct Prompt]  â”€â”€â†’  System Prompt + Retrieved Context + User Query
    â”‚
    â–¼
[LLM Inference]  â”€â”€â†’  OpenAI / Google Gemini / Ollama (local)
    â”‚
    â–¼
[Stream Response]  â”€â”€â†’  Markdown rendered in real-time
```

**Key Design Decisions:**
- No proprietary backend â€” direct browser â†” LLM provider communication.
- Dual vector store with automatic fallback for offline resilience.
- All API keys stored in browser `localStorage` and sent only to their respective providers.

---

## ğŸ› ï¸ Tech Stack

### Core Framework
| Technology | Version | Role |
|---|---|---|
| [React](https://react.dev/) | 19.x | UI component framework |
| [TypeScript](https://www.typescriptlang.org/) | 5.9.x | Type-safe development |
| [Vite](https://vitejs.dev/) | 7.x | Build tool & dev server |

### AI & Machine Learning
| Technology | Role |
|---|---|
| [@xenova/transformers](https://huggingface.co/docs/transformers.js) | In-browser embeddings (WebAssembly, no API key) |
| [OpenAI API](https://platform.openai.com/) | GPT models + OpenAI embeddings |
| [Google Gemini API](https://ai.google.dev/) | Gemini models + Gemini embeddings |
| [Ollama](https://ollama.com/) | Local LLM inference (Llama 3, Mistral, etc.) |

### Storage & Vector Search
| Technology | Role |
|---|---|
| [ChromaDB](https://www.trychroma.com/) | Primary vector database |
| IndexedDB | Browser-native fallback vector store |
| LocalStorage | User settings & API key persistence |

### Document Processing
| Technology | Role |
|---|---|
| [pdfjs-dist](https://mozilla.github.io/pdf.js/) | PDF text extraction |
| Custom Web Scraper | HTML content extraction from URLs |

### Rendering
| Technology | Role |
|---|---|
| [react-markdown](https://github.com/remarkjs/react-markdown) | Markdown rendering for AI responses |
| [remark-gfm](https://github.com/remarkjs/remark-gfm) | GitHub Flavored Markdown support (tables, task lists) |

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** v18 or higher ([Download](https://nodejs.org/))
- **Ollama** *(optional â€” only for local LLMs)*: [Download Ollama](https://ollama.com/)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/sunipa21/AI_Enabled_Knowledge_Management.git
cd AI_Enabled_Knowledge_Management

# 2. Install dependencies
npm install

# 3. Start the development server
npm run dev
```

Open **http://localhost:5173** in your browser.

### Production Build

```bash
npm run build       # Outputs to dist/
npm run preview     # Preview the production build locally
```

---

## âš™ï¸ Configuration

All configuration is done inside the app's **Settings panel** (click the âš™ï¸ gear icon).

### LLM Providers

| Provider | Setup |
|---|---|
| **OpenAI** | Paste your [OpenAI API Key](https://platform.openai.com/api-keys) |
| **Google Gemini** | Paste your [Gemini API Key](https://aistudio.google.com/app/apikey) |
| **Ollama (Local)** | Run Ollama locally â€” no API key required |

### Ollama CORS Setup

If using Ollama, you must allow browser-based requests:

```bash
# macOS / Linux
OLLAMA_ORIGINS="*" ollama serve

# Windows (PowerShell)
$env:OLLAMA_ORIGINS="*"; ollama serve
```

Then pull a model:

```bash
ollama pull llama3        # Recommended
ollama pull mistral       # Alternative
```

### Embedding Providers

Configure in Settings â†’ Embeddings:
- **Transformers.js** â€” Fully local, no API key required *(recommended default)*
- **OpenAI Embeddings** â€” Requires OpenAI API key
- **Gemini Embeddings** â€” Requires Gemini API key

---

## ğŸ“¸ Screenshots

**Settings Interface:**

![Settings â€” HuggingFace](https://github.com/user-attachments/assets/08c31ca7-5af0-4d86-a836-53851bbf7918)
![Settings â€” Ollama](https://github.com/user-attachments/assets/af46189d-c553-4d31-a1a4-040b48374f94)

---

## ğŸ“‚ Project Structure

```
AI_Enabled_Knowledge_Management/
â”œâ”€â”€ public/                     # Static assets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/             # UI components
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx   # Main chat UI with streaming
â”‚   â”‚   â”œâ”€â”€ KnowledgeBase.tsx   # Document management panel
â”‚   â”‚   â”œâ”€â”€ Settings.tsx        # Settings & config panel
â”‚   â”‚   â”œâ”€â”€ SettingsModal.tsx   # Modal wrapper for settings
â”‚   â”‚   â””â”€â”€ VoiceInput.tsx      # Voice input component
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useVoice.ts         # Voice interaction hook
â”‚   â”œâ”€â”€ mocks/
â”‚   â”‚   â””â”€â”€ chroma-default-embed.ts  # ChromaDB no-op embedding shim
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm/                # LLM provider integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.ts       # Google Gemini integration
â”‚   â”‚   â”‚   â”œâ”€â”€ huggingface.ts  # HuggingFace integration
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts        # Provider router
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama.ts       # Ollama integration
â”‚   â”‚   â”‚   â””â”€â”€ openai.ts       # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ chroma-db.ts        # ChromaDB vector store
â”‚   â”‚   â”œâ”€â”€ embeddings.ts       # Embedding provider abstraction
â”‚   â”‚   â”œâ”€â”€ knowledge-base.ts   # RAG orchestration logic
â”‚   â”‚   â”œâ”€â”€ pdf-parser.ts       # PDF text extraction
â”‚   â”‚   â”œâ”€â”€ speech-recognition.ts  # Browser speech API
â”‚   â”‚   â”œâ”€â”€ text-to-speech.ts   # TTS service
â”‚   â”‚   â”œâ”€â”€ vector-db.ts        # IndexedDB vector store (fallback)
â”‚   â”‚   â”œâ”€â”€ web-scraper.ts      # URL content extractor
â”‚   â”‚   â””â”€â”€ web-search.ts       # Web search integration
â”‚   â”œâ”€â”€ types.ts                # Shared TypeScript types
â”‚   â”œâ”€â”€ App.tsx                 # Root application component
â”‚   â””â”€â”€ main.tsx                # Entry point
â”œâ”€â”€ docs/                       # Project wiki
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ vite.config.ts
```

---

## ğŸ—ºï¸ Roadmap

- [ ] Support for more document formats (DOCX, TXT, Markdown)
- [ ] Export and import knowledge base
- [ ] Export chat conversations
- [ ] Advanced filtering and search options
- [ ] Document folders and tagging
- [ ] Multi-language support
- [ ] Mobile-responsive layout enhancements
- [ ] Cloud sync for knowledge base (opt-in)
- [ ] Collaborative shared knowledge bases

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how to get started:

1. **Fork** the repository
2. **Create a branch**: `git checkout -b feature/your-feature-name`
3. **Commit your changes**: `git commit -m 'feat: add your feature'`
4. **Push to branch**: `git push origin feature/your-feature-name`
5. **Open a Pull Request** against `main`

Please ensure your code follows the existing TypeScript patterns and passes the linter:

```bash
npm run lint
```

---

## ğŸ“„ License

This project is licensed under the **MIT License**. See [LICENSE](LICENSE) for details.

---

## ğŸ“š Documentation

Full documentation is available in the [`docs/`](docs/Home.md) directory:

- [Getting Started](docs/Getting-Started.md)
- [Architecture](docs/Architecture.md)
- [Features](docs/Features.md)
- [API Reference](docs/API-Reference.md)
- [Git Workflow](docs/Git-Workflow.md)
